{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine-Learning-Spotify-seg2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lWYxOKOacFG"
      },
      "source": [
        "# Standard code for starting Spark\n",
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.2'\n",
        "spark_version = 'spark-3.<enter version>'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX9ukBg8awlk"
      },
      "source": [
        "# Standard Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Wi5OS-b76t"
      },
      "source": [
        " # Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url=\"https://<bucket name>.s3.amazonaws.com/[INSERT FILE NAME].csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "[FILE NAME]_df = spark.read.csv(SparkFiles.get(\"user_data.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "\n",
        "# Show DataFrame\n",
        "[FILE NAME]df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eIbv4xkgmZa"
      },
      "source": [
        "# Convert Spark DataFrame to Pandas DataFrame\n",
        "dataframe = pd.DataFrame([FILE NAME]df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4D-sDsV6q_6"
      },
      "source": [
        "# Does the database merge the track and artist tables?\n",
        "# If not, load in and merge artists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DARQAHusliUA"
      },
      "source": [
        "# Import dependencies for Machine Learning\n",
        " import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import fcluster, linkage, dendrogram\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import hvplot.pandas\n",
        "from path import Path\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWPBUinEqEsK"
      },
      "source": [
        "# Exploratory Data to understand how we need to preprocess\n",
        "# Explore popularity range - over 75? over 50?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_5vrMcuf3v"
      },
      "source": [
        "# Preprocessing\n",
        "# US only\n",
        "# Popularity? What's a good cut off?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE80W3JI_4PB"
      },
      "source": [
        "# Feature selection: "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3lVJONAzmj7"
      },
      "source": [
        "# Use Hierarchical clustering\n",
        "# Read data from DB using PySpark\n",
        "# Load in Track.csv from S3 into a DataFrame\n",
        "\n",
        "# Normalize data\n",
        "from sklearn.preprocessing import normalize\n",
        "data_scaled = normalize(data)\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
        "data_scaled.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-tvzYCS72XC"
      },
      "source": [
        "\n",
        "# Create hierarchal clustering array using n_clusters determined from dendrogram analysis\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "cluster = AgglomerativeClustering(n_clusters=X, affinity='euclidean', linkage='ward')  \n",
        "cluster.fit_predict(data_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbUGCpj67_Vc"
      },
      "source": [
        "# Plot scatter plot of clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_kuF-HE8As3"
      },
      "source": [
        "# Trying the next machine learning model\n",
        "# Which one shall I pick? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG6WlYk0AB4V"
      },
      "source": [
        "# Does using PCA help? Some clusters are opposite/inverse of others, so it might hurt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OJSvYNyAzen"
      },
      "source": [
        "# Going with a standard test train split. There is no apparent mismatch in sizes of different pieces of the data set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyw1yUADBPUC"
      },
      "source": [
        "# Go through a few models. 3 maybe? Why do I think the best performing model is best performing?\n",
        "\n",
        "# Notes from class! Is this data set actually labeled? Maybe I want to see if this can predict genre?\n",
        "# It's a lot of labels tho\n",
        "# Maybe we cluster and compare genres that get clustered together\n",
        "# I think we don't need deep learning - looking at 100s of columns\n",
        "# But we do have a lot of data - maybe we could look at that!\n",
        "# Or maybe we could talk about that as a future learning\n",
        "# K Means? Check an elbow curve out!\n",
        "# How would I design a neural network? Use that loop to pick the number of features?\n",
        "# How accurate/good is each model?\n",
        "# Were we able to use a simple model?\n",
        "# Do we get similar results each time? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeBb4eUvrzS_"
      },
      "source": [
        "# I think after the dendrogram, I'll do k means clustering and round it out with a neural network\n",
        "# Question is, can we predict the genre lable?\n",
        "# Talk about stuff over time for the tableau bit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBICku2h6FR5"
      },
      "source": [
        "#K Means Clustering\n",
        "#Begin with elbow graph to determine how many clusters we might want\n",
        "inertia = []\n",
        "k = list(range(1, 11))\n",
        "# Calculate the inertia for the range of K values\n",
        "for i in k:\n",
        "   km = KMeans(n_clusters=i, random_state=0)\n",
        "   km.fit(df_shopping)\n",
        "   inertia.append(km.inertia_)\n",
        "#Create elbow curve in hvPlot\n",
        "elbow_data = {\"k\":k, \"inertia\":inertia}\n",
        "df_elbow = pd.DataFrame(elbow_data)\n",
        "df_elbow.hvplot.line(x-\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVJVvY8yBWFS"
      },
      "source": [
        "# Create K Means Model with X clusters (from elbow plot)\n",
        "model = KMeans(n_clusters=3, random_state=42).fit(X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9C7m4qhBk_J"
      },
      "source": [
        "# Calculate predicted values.\n",
        "y_pred = model.predict(X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl5elaKvBrlQ"
      },
      "source": [
        "# Add predicted values onto the original dataframe\n",
        "df_y = pd.DataFrame(y_pred, columns=['Cluster'])\n",
        "combined = df.join(df_y, how='inner')\n",
        "combined.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLticF67xDee"
      },
      "source": [
        "# Plot clusters"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}